This is for 1-hot vector for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 1 0]
 [0 2 1]
 [1 0 4]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.50      0.50      0.50         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.80      0.80      0.80         5

    accuracy                           0.70        10
   macro avg       0.66      0.66      0.66        10
weighted avg       0.70      0.70      0.70        10

Accuracy (Decision Tree): 0.7000
Macro-Average F1 (Decision Tree): 0.6556
Weighted-Average F1 (Decision Tree): 0.7000
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
------------------------------------------------------
This is for 1-hot vector for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 1 0]
 [0 2 1]
 [1 0 4]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.50      0.50      0.50         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.80      0.80      0.80         5

    accuracy                           0.70        10
   macro avg       0.66      0.66      0.66        10
weighted avg       0.70      0.70      0.70        10

Accuracy (Decision Tree): 0.7000
Macro-Average F1 (Decision Tree): 0.6556
Weighted-Average F1 (Decision Tree): 0.7000
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
------------------------------------------------------
This is for 1-hot vector for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 1 0]
 [0 2 1]
 [1 0 4]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.50      0.50      0.50         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.80      0.80      0.80         5

    accuracy                           0.70        10
   macro avg       0.66      0.66      0.66        10
weighted avg       0.70      0.70      0.70        10

Accuracy (Decision Tree): 0.7000
Macro-Average F1 (Decision Tree): 0.6556
Weighted-Average F1 (Decision Tree): 0.7000
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
------------------------------------------------------
This is for 1-hot vector for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 1 0]
 [0 2 1]
 [1 0 4]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.50      0.50      0.50         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.80      0.80      0.80         5

    accuracy                           0.70        10
   macro avg       0.66      0.66      0.66        10
weighted avg       0.70      0.70      0.70        10

Accuracy (Decision Tree): 0.7000
Macro-Average F1 (Decision Tree): 0.6556
Weighted-Average F1 (Decision Tree): 0.7000
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
------------------------------------------------------
This is for 1-hot vector for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 1 0]
 [0 2 1]
 [1 0 4]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.50      0.50      0.50         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.80      0.80      0.80         5

    accuracy                           0.70        10
   macro avg       0.66      0.66      0.66        10
weighted avg       0.70      0.70      0.70        10

Accuracy (Decision Tree): 0.7000
Macro-Average F1 (Decision Tree): 0.6556
Weighted-Average F1 (Decision Tree): 0.7000
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.8000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 1 0]
 [0 3 0]
 [3 0 2]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.25      0.50      0.33         2
      Type_I       0.75      1.00      0.86         3
      Type_M       1.00      0.40      0.57         5

    accuracy                           0.60        10
   macro avg       0.67      0.63      0.59        10
weighted avg       0.78      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.5873
Weighted-Average F1 (Top Decision Tree): 0.6095

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
Precision (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.7500
Class 2: 1.0000
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.4000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 1 0]
 [0 3 0]
 [3 0 2]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.25      0.50      0.33         2
      Type_I       0.75      1.00      0.86         3
      Type_M       1.00      0.40      0.57         5

    accuracy                           0.60        10
   macro avg       0.67      0.63      0.59        10
weighted avg       0.78      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.5873
Weighted-Average F1 (Top Decision Tree): 0.6095

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
Precision (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.7500
Class 2: 1.0000
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.4000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 1 0]
 [0 2 1]
 [2 0 3]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.33      0.50      0.40         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.75      0.60      0.67         5

    accuracy                           0.60        10
   macro avg       0.58      0.59      0.58        10
weighted avg       0.64      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.5778
Weighted-Average F1 (Top Decision Tree): 0.6133

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
Precision (Top Decision Tree): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.6000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 1 0]
 [0 2 1]
 [2 0 3]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.33      0.50      0.40         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.75      0.60      0.67         5

    accuracy                           0.60        10
   macro avg       0.58      0.59      0.58        10
weighted avg       0.64      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.5778
Weighted-Average F1 (Top Decision Tree): 0.6133

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
Precision (Top Decision Tree): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.6000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 1 0]
 [0 2 1]
 [2 0 3]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

      Type_F       0.33      0.50      0.40         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.75      0.60      0.67         5

    accuracy                           0.60        10
   macro avg       0.58      0.59      0.58        10
weighted avg       0.64      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.5778
Weighted-Average F1 (Top Decision Tree): 0.6133

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10}
Precision (Top Decision Tree): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.6667
Class 2: 0.6000
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[2 0 0]
 [1 2 0]
 [5 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.25      1.00      0.40         2
      Type_I       1.00      0.67      0.80         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.40        10
   macro avg       0.42      0.56      0.40        10
weighted avg       0.35      0.40      0.32        10

Accuracy (Top Multi-Layer Perceptron): 0.4000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.4000
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.3200
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.3200

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
{'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[2 0 0]
 [3 0 0]
 [5 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.20      1.00      0.33         2
      Type_I       0.00      0.00      0.00         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Top Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.0667
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.0667

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
{'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [1 2 0]
 [5 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.14      0.50      0.22         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.30        10
   macro avg       0.27      0.39      0.30        10
weighted avg       0.23      0.30      0.24        10

Accuracy (Top Multi-Layer Perceptron): 0.3000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.2963
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [1 2 0]
 [5 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.14      0.50      0.22         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.30        10
   macro avg       0.27      0.39      0.30        10
weighted avg       0.23      0.30      0.24        10

Accuracy (Top Multi-Layer Perceptron): 0.3000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.2963
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
{'activation': 'tanh', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [1 2 0]
 [5 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

      Type_F       0.14      0.50      0.22         2
      Type_I       0.67      0.67      0.67         3
      Type_M       0.00      0.00      0.00         5

    accuracy                           0.30        10
   macro avg       0.27      0.39      0.30        10
weighted avg       0.23      0.30      0.24        10

Accuracy (Top Multi-Layer Perceptron): 0.3000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.2963
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.2444

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.3333
Class 1: 0.6667
Class 2: 0.7500
Recall (Multi-Layer Perceptron): 
{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
Summary: 
Average Accuracy: 0.4500, Variance: 0.0435
 Average Macro-Average F1: 0.4071, Variance: 0.0512
 Average Weighted-Average F1: 0.4006, Variance: 0.0710
------------------------------------------------------
This is for categories yourself for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[2 0 0]
 [1 5 0]
 [0 0 2]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

           2       0.67      1.00      0.80         2
           1       1.00      0.83      0.91         6
           0       1.00      1.00      1.00         2

    accuracy                           0.90        10
   macro avg       0.89      0.94      0.90        10
weighted avg       0.93      0.90      0.91        10

Accuracy (Decision Tree): 0.9000
Macro-Average F1 (Decision Tree): 0.9030
Weighted-Average F1 (Decision Tree): 0.9055
Precision (Decision Tree): 
Class 0: 0.6667
Class 1: 1.0000
Class 2: 1.0000
Recall (Decision Tree):
Class 0: 1.0000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
This is for categories yourself for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[2 0 0]
 [1 5 0]
 [0 0 2]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

           2       0.67      1.00      0.80         2
           1       1.00      0.83      0.91         6
           0       1.00      1.00      1.00         2

    accuracy                           0.90        10
   macro avg       0.89      0.94      0.90        10
weighted avg       0.93      0.90      0.91        10

Accuracy (Decision Tree): 0.9000
Macro-Average F1 (Decision Tree): 0.9030
Weighted-Average F1 (Decision Tree): 0.9055
Precision (Decision Tree): 
Class 0: 0.6667
Class 1: 1.0000
Class 2: 1.0000
Recall (Decision Tree):
Class 0: 1.0000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
This is for categories yourself for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[2 0 0]
 [1 5 0]
 [0 0 2]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

           2       0.67      1.00      0.80         2
           1       1.00      0.83      0.91         6
           0       1.00      1.00      1.00         2

    accuracy                           0.90        10
   macro avg       0.89      0.94      0.90        10
weighted avg       0.93      0.90      0.91        10

Accuracy (Decision Tree): 0.9000
Macro-Average F1 (Decision Tree): 0.9030
Weighted-Average F1 (Decision Tree): 0.9055
Precision (Decision Tree): 
Class 0: 0.6667
Class 1: 1.0000
Class 2: 1.0000
Recall (Decision Tree):
Class 0: 1.0000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
This is for categories yourself for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[1 0 1]
 [1 5 0]
 [0 0 2]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

           2       0.50      0.50      0.50         2
           1       1.00      0.83      0.91         6
           0       0.67      1.00      0.80         2

    accuracy                           0.80        10
   macro avg       0.72      0.78      0.74        10
weighted avg       0.83      0.80      0.81        10

Accuracy (Decision Tree): 0.8000
Macro-Average F1 (Decision Tree): 0.7364
Weighted-Average F1 (Decision Tree): 0.8055
Precision (Decision Tree): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Decision Tree):
Class 0: 0.5000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
This is for categories yourself for abalone
------------------------------------------------------
(A)Confusion Matrix (Decision Tree):
[[2 0 0]
 [1 5 0]
 [0 0 2]]
Classification Report (Decision Tree):
              precision    recall  f1-score   support

           2       0.67      1.00      0.80         2
           1       1.00      0.83      0.91         6
           0       1.00      1.00      1.00         2

    accuracy                           0.90        10
   macro avg       0.89      0.94      0.90        10
weighted avg       0.93      0.90      0.91        10

Accuracy (Decision Tree): 0.9000
Macro-Average F1 (Decision Tree): 0.9030
Weighted-Average F1 (Decision Tree): 0.9055
Precision (Decision Tree): 
Class 0: 0.6667
Class 1: 1.0000
Class 2: 1.0000
Recall (Decision Tree):
Class 0: 1.0000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[2 0 0]
 [0 5 1]
 [1 0 1]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

           2       0.67      1.00      0.80         2
           1       1.00      0.83      0.91         6
           0       0.50      0.50      0.50         2

    accuracy                           0.80        10
   macro avg       0.72      0.78      0.74        10
weighted avg       0.83      0.80      0.81        10

Accuracy (Top Decision Tree): 0.8000
Macro-Average F1 (Top Decision Tree): 0.7364
Weighted-Average F1 (Top Decision Tree): 0.8055

Best Hyperparameters (Top Decision Tree):
{'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2}
Precision (Top Decision Tree): 
Class 0: 0.6667
Class 1: 1.0000
Class 2: 0.5000
Recall (Top Decision Tree): 
Class 0: 1.0000
Class 1: 0.8333
Class 2: 0.5000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 0 1]
 [1 5 0]
 [2 0 0]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

           2       0.25      0.50      0.33         2
           1       1.00      0.83      0.91         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.42      0.44      0.41        10
weighted avg       0.65      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.4141
Weighted-Average F1 (Top Decision Tree): 0.6121

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}
Precision (Top Decision Tree): 
Class 0: 0.2500
Class 1: 1.0000
Class 2: 0.0000
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.8333
Class 2: 0.0000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 0 1]
 [1 5 0]
 [2 0 0]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

           2       0.25      0.50      0.33         2
           1       1.00      0.83      0.91         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.42      0.44      0.41        10
weighted avg       0.65      0.60      0.61        10

Accuracy (Top Decision Tree): 0.6000
Macro-Average F1 (Top Decision Tree): 0.4141
Weighted-Average F1 (Top Decision Tree): 0.6121

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}
Precision (Top Decision Tree): 
Class 0: 0.2500
Class 1: 1.0000
Class 2: 0.0000
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.8333
Class 2: 0.0000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[2 0 0]
 [1 5 0]
 [2 0 0]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

           2       0.40      1.00      0.57         2
           1       1.00      0.83      0.91         6
           0       0.00      0.00      0.00         2

    accuracy                           0.70        10
   macro avg       0.47      0.61      0.49        10
weighted avg       0.68      0.70      0.66        10

Accuracy (Top Decision Tree): 0.7000
Macro-Average F1 (Top Decision Tree): 0.4935
Weighted-Average F1 (Top Decision Tree): 0.6597

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 5}
Precision (Top Decision Tree): 
Class 0: 0.4000
Class 1: 1.0000
Class 2: 0.0000
Recall (Top Decision Tree): 
Class 0: 1.0000
Class 1: 0.8333
Class 2: 0.0000
------------------------------------------------------
------------------------------------------------------
(B)Confusion Matrix (Top Decision Tree):
[[1 0 1]
 [1 5 0]
 [0 0 2]]
Classification Report (Top Decision Tree):
              precision    recall  f1-score   support

           2       0.50      0.50      0.50         2
           1       1.00      0.83      0.91         6
           0       0.67      1.00      0.80         2

    accuracy                           0.80        10
   macro avg       0.72      0.78      0.74        10
weighted avg       0.83      0.80      0.81        10

Accuracy (Top Decision Tree): 0.8000
Macro-Average F1 (Top Decision Tree): 0.7364
Weighted-Average F1 (Top Decision Tree): 0.8055

Best Hyperparameters (Top Decision Tree):
{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}
Precision (Top Decision Tree): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Top Decision Tree): 
Class 0: 0.5000
Class 1: 0.8333
Class 2: 1.0000
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [6 0 0]
 [2 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.20      1.00      0.33         2
           1       0.00      0.00      0.00         6
           0       0.00      0.00      0.00         2

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [6 0 0]
 [2 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.20      1.00      0.33         2
           1       0.00      0.00      0.00         6
           0       0.00      0.00      0.00         2

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[1 1 0]
 [0 6 0]
 [2 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      0.50      0.40         2
           1       0.86      1.00      0.92         6
           0       0.00      0.00      0.00         2

    accuracy                           0.70        10
   macro avg       0.40      0.50      0.44        10
weighted avg       0.58      0.70      0.63        10

Accuracy (Multi-Layer Perceptron): 0.7000
Macro-Average F1 (Multi-Layer Perceptron): 0.4410
Weighted-Average F1 (Multi-Layer Perceptron): 0.6338
Precision (Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [6 0 0]
 [2 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.20      1.00      0.33         2
           1       0.00      0.00      0.00         6
           0       0.00      0.00      0.00         2

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(C)Confusion Matrix (Multi-Layer Perceptron):
[[2 0 0]
 [6 0 0]
 [2 0 0]]
Classification Report (Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.20      1.00      0.33         2
           1       0.00      0.00      0.00         6
           0       0.00      0.00      0.00         2

    accuracy                           0.20        10
   macro avg       0.07      0.33      0.11        10
weighted avg       0.04      0.20      0.07        10

Accuracy (Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Multi-Layer Perceptron): 0.1111
Weighted-Average F1 (Multi-Layer Perceptron): 0.0667
Precision (Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [0 5 1]
 [2 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      0.50      0.40         2
           1       0.83      0.83      0.83         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.39      0.44      0.41        10
weighted avg       0.57      0.60      0.58        10

Accuracy (Top Multi-Layer Perceptron): 0.6000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.4111
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
{'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [0 5 1]
 [2 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      0.50      0.40         2
           1       0.83      0.83      0.83         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.39      0.44      0.41        10
weighted avg       0.57      0.60      0.58        10

Accuracy (Top Multi-Layer Perceptron): 0.6000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.4111
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
{'activation': 'relu', 'hidden_layer_sizes': (10, 10, 10), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[2 0 0]
 [2 0 4]
 [2 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      1.00      0.50         2
           1       0.00      0.00      0.00         6
           0       0.00      0.00      0.00         2

    accuracy                           0.20        10
   macro avg       0.11      0.33      0.17        10
weighted avg       0.07      0.20      0.10        10

Accuracy (Top Multi-Layer Perceptron): 0.2000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.1667
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.1000
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.1000

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
{'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [0 5 1]
 [2 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      0.50      0.40         2
           1       0.83      0.83      0.83         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.39      0.44      0.41        10
weighted avg       0.57      0.60      0.58        10

Accuracy (Top Multi-Layer Perceptron): 0.6000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.4111
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
{'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
------------------------------------------------------
(D)Confusion Matrix (Top Multi-Layer Perceptron):
[[1 1 0]
 [0 5 1]
 [2 0 0]]
Classification Report (Top Multi-Layer Perceptron):
              precision    recall  f1-score   support

           2       0.33      0.50      0.40         2
           1       0.83      0.83      0.83         6
           0       0.00      0.00      0.00         2

    accuracy                           0.60        10
   macro avg       0.39      0.44      0.41        10
weighted avg       0.57      0.60      0.58        10

Accuracy (Top Multi-Layer Perceptron): 0.6000
Macro-Average F1 (Top Multi-Layer Perceptron): 0.4111
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800
Weighted-Average F1 (Top Multi-Layer Perceptron): 0.5800

Best Hyperparameters (Top Multi-Layer Perceptron):
Precision (Top Multi-Layer Perceptron): 
Class 0: 0.5000
Class 1: 1.0000
Class 2: 0.6667
Recall (Multi-Layer Perceptron): 
{'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
------------------------------------------------------
Summary: 
Average Accuracy: 0.6000, Variance: 0.0650
 Average Macro-Average F1: 0.4920, Variance: 0.0791
 Average Weighted-Average F1: 0.5621, Variance: 0.0933
------------------------------------------------------
